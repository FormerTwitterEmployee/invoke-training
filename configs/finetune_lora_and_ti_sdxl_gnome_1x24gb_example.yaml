# Training mode: Finetuning with LoRA and Textual Inversion
# Base model:    SDXL 1.0
# GPU:           1 x 24GB

type: FINETUNE_LORA_AND_TI_SDXL
seed: 1
base_output_dir: output/lora_and_ti_sdxl_bruce_the_gnome

optimizer:
  optimizer_type: AdamW
  learning_rate: 2e-3

lr_warmup_steps: 200
lr_scheduler: constant

data_loader:
  type: TEXTUAL_INVERSION_SD_DATA_LOADER
  dataset:
    type: IMAGE_DIR_DATASET
    dataset_dir: "sample_data/bruce_the_gnome"
    keep_in_memory: True
  caption_preset: object
  resolution: 1024
  center_crop: True
  random_flip: False
  shuffle_caption_delimiter: null
  dataloader_num_workers: 4

# General
model: stabilityai/stable-diffusion-xl-base-1.0
vae_model: madebyollin/sdxl-vae-fp16-fix
num_vectors: 2
placeholder_token: "bruce_the_gnome"
initializer_token: "gnome"
cache_vae_outputs: False
gradient_accumulation_steps: 1
mixed_precision: fp16
xformers: False
gradient_checkpointing: True
max_train_steps: 500
save_every_n_epochs: 20
validate_every_n_epochs: 20
save_every_n_steps: null
max_checkpoints: 50
validation_prompts:
  - A photo of bruce_the_gnome at the beach
  - A photo of bruce_the_gnome reading a book
train_batch_size: 1
num_validation_images_per_prompt: 3
