# Training mode: Direct Preference Optimization LoRA Training
# Dataset: A small subset of the pickapic_v2 dataset.
# Base model:    SD 1.5
# GPU:           1 x 24GB
#
# Training takes ~2 hours on a single RTX 4090.

type: DIRECT_PREFERENCE_OPTIMIZATION_LORA_SD
seed: 1
output:
  base_output_dir: output/dpo

optimizer:
  learning_rate: 1e-4
  lr_warmup_steps: 200
  lr_scheduler: cosine

  optimizer:
    optimizer_type: AdamW
    weight_decay: 1e-2

data_loader:
  type: IMAGE_PAIR_PREFERENCE_SD_DATA_LOADER
  dataset:
    type: HF_HUB_IMAGE_PAIR_PREFERENCE_DATASET
  image_transforms:
    resolution: 512

# General
model: runwayml/stable-diffusion-v1-5
gradient_accumulation_steps: 2
mixed_precision: fp16
xformers: False
gradient_checkpointing: True
max_train_steps: 5000
save_every_n_epochs: 1
save_every_n_steps: null
max_checkpoints: 100
validation_prompts:
  - A monk in an orange robe by a round window in a spaceship in dramatic lighting
  - A galaxy-colored figurine is floating over the sea at sunset, photorealistic
  - Concept art of a mythical sky alligator with wings, nature documentary
validate_every_n_epochs: 1
train_batch_size: 4
num_validation_images_per_prompt: 1
