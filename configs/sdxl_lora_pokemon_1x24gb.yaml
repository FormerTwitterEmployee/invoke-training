# Training mode: Finetuning with LoRA
# Base model:    SDXL 1.0
# Dataset:       Pokemon
# GPU:           1 x 24GB

# Notes:
# This config file has been optimized for the primary goal of achieving reasonable results *quickly* (<15mins) for demo
# purposes.
type: SDXL_LORA
seed: 1
base_output_dir: output/finetune_lora_sdxl_pokemon/

optimizer:
  optimizer_type: Prodigy
  learning_rate: 1.0
  weight_decay: 0.01
  use_bias_correction: True
  safeguard_warmup: True

data_loader:
  type: IMAGE_CAPTION_SD_DATA_LOADER
  dataset:
    type: HF_HUB_IMAGE_CAPTION_DATASET
    dataset_name: lambdalabs/pokemon-blip-captions
  resolution: 512

# General
model: stabilityai/stable-diffusion-xl-base-1.0
vae_model: madebyollin/sdxl-vae-fp16-fix
gradient_accumulation_steps: 1
mixed_precision: fp16
xformers: False
gradient_checkpointing: True

max_train_epochs: 3
save_every_n_epochs: 1
validate_every_n_epochs: 1

max_checkpoints: 5
validation_prompts:
  - A cute yoda pokemon creature.
  - A cute astronaut pokemon creature.
train_batch_size: 6
num_validation_images_per_prompt: 3
